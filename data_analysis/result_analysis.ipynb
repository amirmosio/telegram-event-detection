{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from model_training import print_model_evaluation\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, X_train, y_train, X_test, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_evaluation(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt=\"d\", cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"important features\")\n",
    "importances = model.feature_importances_\n",
    "columns_enumeration = [(column, i) for i, column in enumerate(X_train.columns)]\n",
    "columns_enumeration.sort()\n",
    "for column, i in columns_enumeration:\n",
    "    print(f\"{column} {round(importances[i], ndigits=3)}\", end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Importance Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Permutation Importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation Importance evaluates the drop in model performance when the values of a feature are randomly shuffled. A larger drop indicates higher importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance_rf = permutation_importance(model, X_train, y_train, n_repeats=10, random_state=42)\n",
    "sorted_importances_idx = perm_importance_rf.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    perm_importance_rf.importances[sorted_importances_idx].T,\n",
    "    columns=X_test.columns[sorted_importances_idx],\n",
    ")\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permutation Importances Random Forest (train set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree's Feature Importance from Mean Decrease in Impurity (MDI): the impurity-based feature importance ranks the numerical features to be the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns\n",
    "\n",
    "mdi_importances = pd.Series(\n",
    "    model[-1].feature_importances_, index=feature_names\n",
    ").sort_values(ascending=True)\n",
    "ax = mdi_importances.plot.barh()#color = )\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicted vs True new conversations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/new_conversation.csv')\n",
    "id_test = X_test['id']\n",
    "subset_df = df[df['id'].isin(id_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlight using different colors the *true* (black) and *predicted* (blue) changes in conversations detected by RandomForest on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = subset_df.groupby('group')\n",
    "num_plots = len(grouped)\n",
    "fig, axes = plt.subplots(num_plots, 1, figsize=(15, 5*num_plots))\n",
    "\n",
    "true_drifts = []\n",
    "predicted_drifts = []\n",
    "\n",
    "for i, (group, group_data) in enumerate(grouped):\n",
    "    n_drift_true = 0\n",
    "    n_drift_predicted = 0\n",
    "    new_conversation = group_data['new_conversation'] == 'yes'\n",
    "    axes[i].scatter(group_data['date'], new_conversation, label=group, marker='.',linewidth = 2, color='#FF5733')\n",
    "\n",
    "    prev_status = None\n",
    "    for date, message_id, status in zip(group_data['date'], group_data['index'], new_conversation): #CHECK FOR INDEX OR ID\n",
    "        if prev_status is not None and status != prev_status and prev_status == True:\n",
    "            axes[i].axvline(x=date, color='black', linestyle='-', linewidth=0.3, label = 'True Change')\n",
    "            n_drift_true += 1\n",
    "\n",
    "        if y_test[message_id] == True: #CHECK WITH THE ACTUAL FORMAT OF TEST\n",
    "            axes[i].axvline(x=date, color='blue', linestyle='-', linewidth=0.3, label = 'Predicted Change')\n",
    "            n_drift_predicted += 1\n",
    "            \n",
    "        prev_status = status\n",
    "\n",
    "    axes[i].set_title(f'Drift-Group: {group}')\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel('New Conversation')\n",
    "\n",
    "    true_drifts.append((n_drift_true, group))\n",
    "    predicted_drifts.append((n_drift_predicted, group))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare frequency of *true* and *predicted* changes in conversations detected by RandomForest on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_width = 0.35\n",
    "\n",
    "index = np.arange(len(grouped))\n",
    "\n",
    "plt.barh(index, true_drifts, bar_width, label='True Drifts', color='lightblue')\n",
    "plt.barh(index + bar_width, predicted_drifts, bar_width, label='Predicted Drifts', color='lightgreen')\n",
    "\n",
    "plt.xlabel('Number of Drifts')\n",
    "plt.ylabel('Group')\n",
    "plt.title('Number of True and Predicted Drifts per Group')\n",
    "plt.yticks(index + bar_width / 2, grouped)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
