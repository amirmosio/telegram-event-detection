{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Laser Embedding**"
      ],
      "metadata": {
        "id": "iKKBIpRbwWH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==2.2.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX4Pw4eSZ2VR",
        "outputId": "cfa3df7d-e87c-44f2-fa9d-a057a00c0e0c"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aegj72hlY_Jg",
        "outputId": "a56bdb2b-0ab7-4185-ee3a-85b774471123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q laserembeddings==1.1.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m laserembeddings download-models"
      ],
      "metadata": {
        "id": "OWFlD-9pY_30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d67dda-8e21-4132-dc7a-beb69d95315c"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models into /usr/local/lib/python3.10/dist-packages/laserembeddings/data\n",
            "\n",
            "‚è≥   Downloading https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes...\r‚úÖ   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n",
            "‚úÖ   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n",
            "‚úÖ   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n",
            "\n",
            "‚ú® You're all set!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MocBwStb5hjJ"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv('preprocessed_messages.csv')"
      ],
      "metadata": {
        "id": "pk6W8HfV6X3C"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = dataframe['text']\n",
        "tokenized = dataframe['stemmed_sentence_Porter']"
      ],
      "metadata": {
        "id": "2jW7hNSm6UZA"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langs = [\"en\" for i in range(len(texts))]"
      ],
      "metadata": {
        "id": "dcdap1vV4kc7"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from laserembeddings import Laser\n",
        "\n",
        "laser = Laser()\n",
        "embeddings_text = laser.embed_sentences(\n",
        "    texts,\n",
        "    lang=langs)\n",
        "\n",
        "embeddings_tokenized = laser.embed_sentences(\n",
        "    tokenized,\n",
        "    lang=langs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWQb4XZrp1uU",
        "outputId": "4da33ec5-b7bf-4c73-e8d0-adb8fdc19f4f"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.6 s, sys: 472 ms, total: 6.07 s\n",
            "Wall time: 6.96 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Text embedding shape: ', embeddings_text.shape)\n",
        "print('Tokenized embedding shape: ', embeddings_tokenized.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvMoQoNi8rhI",
        "outputId": "c073894a-30f5-49a5-8076-cb68335622fd"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text embedding shape:  (50, 1024)\n",
            "Tokenized embedding shape:  (50, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('text:', embeddings_text[0], texts[0])\n",
        "print('embeddings:', embeddings_tokenized[0], texts[0], tokenized[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD96Cei876Aa",
        "outputId": "750b8080-fbef-4eae-cab3-9da0a6e9a26d"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: [ 0.0086212  -0.0001213   0.04254882 ...  0.01014943  0.00585767\n",
            "  0.0261275 ] We can do it online so that everyone could join\n",
            "embeddings: [1.4702949e-02 5.2515816e-06 1.8564619e-02 ... 2.1697991e-02 2.4591812e-03\n",
            " 2.8372105e-02] We can do it online so that everyone could join ['onlin', 'everyon', 'could', 'join']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference = 'let s do the meeting'\n",
        "embedding_reference = laser.embed_sentences(\n",
        "    reference,\n",
        "    lang='en')\n",
        "print('text:', embedding_reference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhtcJyKo8JaI",
        "outputId": "d4160fb9-3f7f-4d59-faeb-25f33b4e5729"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: [[ 0.01682114  0.01596329  0.00836292 ...  0.00719668  0.01053112\n",
            "  -0.00772411]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarities_text = cosine_similarity(embedding_reference, embeddings_text)\n",
        "most_similar_text = np.argmax(similarities_text)"
      ],
      "metadata": {
        "id": "HjuwoT7iwkCC"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar_indices_text = np.argsort(similarities_text[0])[:-11:-1]\n",
        "print(texts[most_similar_indices_text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7XrXm_QdGFX",
        "outputId": "1a4576d5-4384-4f2d-cd71-bf4649a4a4dd"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45                                       I vote the 4th\n",
            "1                             I'm ok if we do it online\n",
            "22                                 I manage to add them\n",
            "23                                        I can try now\n",
            "49         We could use our names/surnames concatenated\n",
            "0       We can do it online so that everyone could join\n",
            "8     I coudn't do it directly when saving the messa...\n",
            "27    I pushed the new version of test (just with th...\n",
            "17    It's probably something with the working direc...\n",
            "21    wow,\\r\\ngreat\\r\\nCan you send the csv, I just ...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarities_tokenized = cosine_similarity(embedding_reference, embeddings_tokenized)\n",
        "most_similar_tokenized = np.argmax(similarities_tokenized)"
      ],
      "metadata": {
        "id": "uWUPtWFl8yel"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar_indices_token = np.argsort(similarities_tokenized[0])[:-11:-1]\n",
        "print(texts[most_similar_indices_token], tokenized[most_similar_indices_token])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meneF6eJdShj",
        "outputId": "888a01dd-21a0-4f3f-c601-59f46b1c1edb"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45                                  I vote the 4th\n",
            "49    We could use our names/surnames concatenated\n",
            "22                            I manage to add them\n",
            "23                                   I can try now\n",
            "16                                         Perfect\n",
            "29                                             Yes\n",
            "9                                         perfetto\n",
            "38                               I think it‚Äôs this\n",
            "28                                           great\n",
            "25                                   ahh, too late\n",
            "Name: text, dtype: object 45                                 ['vote', '4th']\n",
            "49    ['could', 'use', 'names/surnam', 'concaten']\n",
            "22                                ['manag', 'add']\n",
            "23                                         ['tri']\n",
            "16                                     ['perfect']\n",
            "29                                          ['ye']\n",
            "9                                     ['perfetto']\n",
            "38                                  ['think', '‚Äô']\n",
            "28                                       ['great']\n",
            "25                            ['ahh', ',', 'late']\n",
            "Name: stemmed_sentence_Porter, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Most similar index:\\ntext: ', most_similar_text, '\\ntokenized: ', most_similar_tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3-CKT-o9mnV",
        "outputId": "42064a99-cb2c-4eba-94ff-7de1d44ba7ad"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar index:\n",
            "text:  45 \n",
            "tokenized:  45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Most similar text:', texts[most_similar_text])\n",
        "print('Most similar tokenized:', texts[most_similar_tokenized], tokenized[most_similar_tokenized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch8O8dxu91WN",
        "outputId": "1659b236-88e8-4427-8781-af4116b840cf"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar text: I vote the 4th\n",
            "Most similar tokenized: I vote the 4th ['vote', '4th']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "------------------------------------"
      ],
      "metadata": {
        "id": "Ca8uyuEU-FAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentence Transformers**"
      ],
      "metadata": {
        "id": "QObyPWALv_vX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsj1nb2yp2mY",
        "outputId": "71595981-32da-48cd-b9f7-5c2b5ffe78b5"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->sentence_transformers) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->sentence_transformers) (0.43.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check https://huggingface.co/sentence-transformers for lower dimensionality transformers"
      ],
      "metadata": {
        "id": "4o8NdbCsnU5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "emodel = SentenceTransformer(\"average_word_embeddings_glove.6B.300d\") #300\n",
        "\n",
        "embedded_texts = emodel.encode(texts)\n",
        "embedded_tokenized = emodel.encode(tokenized)\n",
        "reference_embedding =  emodel.encode(reference)"
      ],
      "metadata": {
        "id": "aeRnXyPLpqrT"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reference_embedding.shape, embedded_texts.shape, embedded_tokenized.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2KnRDwZAehZ",
        "outputId": "1dbc5946-e5fb-470d-e9ce-69d41a618480"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,) (50, 300) (50, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarities_text = cosine_similarity(reference_embedding.reshape(1, -1), embedded_texts)\n",
        "most_similar_text = np.argmax(similarities_text)"
      ],
      "metadata": {
        "id": "wc1JYfn3xRrO"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar_indices = np.argsort(similarities_text[0])[:-11:-1]\n",
        "print(texts[most_similar_indices])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAPbV5sLatfv",
        "outputId": "3446f836-029f-4fda-bfbd-3900a5b1b6bf"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36    I asked them where they want to meet, I'll let...\n",
            "31                 Did you meet the polinetwork‚Äôs guys?\n",
            "30    Yeah,\\r\\nIt's probably ok. He was very support...\n",
            "6     Do you want to meet/call sometime soon or we w...\n",
            "11    If you react with different reactions to this ...\n",
            "38                                    I think it‚Äôs this\n",
            "37                        Is tomorrow at 14 ok for you?\n",
            "23                                        I can try now\n",
            "32    hmm\\r\\nare you sure? did you change the values...\n",
            "47    It would be more convenient to set it related ...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarities_token = cosine_similarity(reference_embedding.reshape(1, -1), embedded_tokenized)\n",
        "most_similar_token = np.argmax(similarities_token)"
      ],
      "metadata": {
        "id": "P7S9wm6LAJeQ"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar_indices_token = np.argsort(similarities_token[0])[:-11:-1]\n",
        "print(texts[most_similar_indices_token], tokenized[most_similar_indices_token])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD_puA-Fcvcw",
        "outputId": "32deb2f1-71da-47f5-8cb4-2201eabd6183"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36    I asked them where they want to meet, I'll let...\n",
            "6     Do you want to meet/call sometime soon or we w...\n",
            "30    Yeah,\\r\\nIt's probably ok. He was very support...\n",
            "31                 Did you meet the polinetwork‚Äôs guys?\n",
            "33    Now it works just fine, I don't know why it di...\n",
            "26    Also, if you want to commit the changes in the...\n",
            "17    It's probably something with the working direc...\n",
            "47    It would be more convenient to set it related ...\n",
            "37                        Is tomorrow at 14 ok for you?\n",
            "13    I guess the csv can be modified once transform...\n",
            "Name: text, dtype: object 36    ['ask', 'want', 'meet', ',', \"'ll\", 'let', 'kn...\n",
            "6     ['want', 'meet/cal', 'sometim', 'soon', 'work'...\n",
            "30    ['yeah', ',', \"'s\", 'probabl', 'ok', '.', 'sup...\n",
            "31             ['meet', 'polinetwork', '‚Äô', 'guy', '?']\n",
            "33    ['work', 'fine', ',', \"n't\", 'know', \"n't\", 'w...\n",
            "26    ['also', ',', 'want', 'commit', 'chang', 'repo...\n",
            "17    [\"'s\", 'probabl', 'someth', 'work', 'directori...\n",
            "47    ['would', 'conveni', 'set', 'relat', 'topic', ...\n",
            "37                        ['tomorrow', '14', 'ok', '?']\n",
            "13    ['guess', 'csv', 'modifi', 'transform', 'dataf...\n",
            "Name: stemmed_sentence_Porter, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Most similar index.\\nText:', most_similar_text, '\\nTokenized:', most_similar_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1OiFrgnxUsq",
        "outputId": "c8d21d57-aaf8-4dc4-f098-38a4deda2911"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar index.\n",
            "Text: 36 \n",
            "Tokenized: 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Most similar text.\\nText:', texts[most_similar_text], '\\nTokenized:', texts[most_similar_token], tokenized[most_similar_token])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDiOxRfbApa-",
        "outputId": "b823547f-adab-4193-d261-e793db01627f"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar text.\n",
            "Text: I asked them where they want to meet, I'll let you know as soon as I receive an answer \n",
            "Tokenized: I asked them where they want to meet, I'll let you know as soon as I receive an answer ['ask', 'want', 'meet', ',', \"'ll\", 'let', 'know', 'soon', 'receiv', 'answer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# other options\n",
        "# https://huggingface.co/spaces/mteb/leaderboard"
      ],
      "metadata": {
        "id": "2zDYzblpqLsM"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply PCA"
      ],
      "metadata": {
        "id": "6yFkLZNnnopU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*PCA on original text and reference*"
      ],
      "metadata": {
        "id": "TNR7G1cDthEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "all_texts = reference + texts\n",
        "all_embeddings = emodel.encode(all_texts)\n",
        "\n",
        "# Apply PCA to the encoded embeddings\n",
        "pca = PCA(n_components=50)\n",
        "pca.fit(all_embeddings)\n",
        "embedded_texts_pca = pca.transform(all_embeddings)\n",
        "\n",
        "reference_embedding_pca = embedded_texts_pca[0]\n",
        "embedded_texts_pca = embedded_texts_pca[1:]\n"
      ],
      "metadata": {
        "id": "JQFUVsJ2s9Hq"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities_text = cosine_similarity(reference_embedding_pca.reshape(1, -1), embedded_texts_pca)\n",
        "most_similar_text = np.argmax(similarities_text)\n",
        "most_similar_indices = np.argsort(similarities_text[0])[:-11:-1]\n",
        "print(texts[most_similar_indices])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKMXy7RUoIbd",
        "outputId": "57b3de33-94e9-48f2-8b9d-9acd49a0742f"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1                             I'm ok if we do it online\n",
            "0       We can do it online so that everyone could join\n",
            "43                                 amidierfan@gmail.com\n",
            "5     Thursday, I'm all available except from 5:15 t...\n",
            "34    @Martinavigano \\r\\nTell me if you could find t...\n",
            "16                                              Perfect\n",
            "9                                              perfetto\n",
            "46    TelegramInfromationSpace\\r\\nAnamolyDetectionBo...\n",
            "20    When I run directly from the terminal I get th...\n",
            "25                                        ahh, too late\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*PCA on tokenized text and original reference (think about tokenizing the reference...)*"
      ],
      "metadata": {
        "id": "Qq6vV9FEtlNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_texts = reference + tokenized\n",
        "all_embeddings = emodel.encode(all_texts)\n",
        "\n",
        "# Apply PCA to the encoded embeddings\n",
        "pca = PCA(n_components=50)\n",
        "pca.fit(all_embeddings)\n",
        "embedded_tokenized_pca = pca.transform(all_embeddings)\n",
        "\n",
        "reference_embedding_pca = embedded_tokenized_pca[0]\n",
        "embedded_tokenized_pca = embedded_tokenized_pca[1:]"
      ],
      "metadata": {
        "id": "3VVUBhP8try6"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities_tokenized = cosine_similarity(reference_embedding_pca.reshape(1, -1), embedded_tokenized_pca)\n",
        "most_similar_tokenized = np.argmax(similarities_tokenized)\n",
        "most_similar_indices = np.argsort(similarities_tokenized[0])[:-11:-1]\n",
        "print(texts[most_similar_indices])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC3hoxfPt7qW",
        "outputId": "d60902e2-9d4c-4fb3-c4f8-71b6e8463192"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27    I pushed the new version of test (just with th...\n",
            "42                       Martina2.vigano@mail.polimi.it\n",
            "41                         lorenzo.mondo@mail.polimi.it\n",
            "40    Do you remember the name of the technique prop...\n",
            "28                                                great\n",
            "15            Could you do it like reactions: {\"ü§û\": 1}?\n",
            "22                                 I manage to add them\n",
            "45                                       I vote the 4th\n",
            "8     I coudn't do it directly when saving the messa...\n",
            "35                        Room 2.1.3, it should be free\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------"
      ],
      "metadata": {
        "id": "dprEFUUXkHjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bert**"
      ],
      "metadata": {
        "id": "b-Kbd3d6wRvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "uAhJjv4OkIaF"
      },
      "execution_count": 141,
      "outputs": []
    }
  ]
}